{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importando o dataset e criando os dados de treino e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>25.380</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>24.990</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>23.570</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>14.910</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>22.540</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>926424</td>\n",
       "      <td>M</td>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>...</td>\n",
       "      <td>25.450</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>926682</td>\n",
       "      <td>M</td>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>...</td>\n",
       "      <td>23.690</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>926954</td>\n",
       "      <td>M</td>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>...</td>\n",
       "      <td>18.980</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>927241</td>\n",
       "      <td>M</td>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>...</td>\n",
       "      <td>25.740</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>92751</td>\n",
       "      <td>B</td>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>9.456</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0      842302         M        17.99         10.38          122.80     1001.0   \n",
       "1      842517         M        20.57         17.77          132.90     1326.0   \n",
       "2    84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3    84348301         M        11.42         20.38           77.58      386.1   \n",
       "4    84358402         M        20.29         14.34          135.10     1297.0   \n",
       "..        ...       ...          ...           ...             ...        ...   \n",
       "564    926424         M        21.56         22.39          142.00     1479.0   \n",
       "565    926682         M        20.13         28.25          131.20     1261.0   \n",
       "566    926954         M        16.60         28.08          108.30      858.1   \n",
       "567    927241         M        20.60         29.33          140.10     1265.0   \n",
       "568     92751         B         7.76         24.54           47.92      181.0   \n",
       "\n",
       "     smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0            0.11840           0.27760         0.30010              0.14710   \n",
       "1            0.08474           0.07864         0.08690              0.07017   \n",
       "2            0.10960           0.15990         0.19740              0.12790   \n",
       "3            0.14250           0.28390         0.24140              0.10520   \n",
       "4            0.10030           0.13280         0.19800              0.10430   \n",
       "..               ...               ...             ...                  ...   \n",
       "564          0.11100           0.11590         0.24390              0.13890   \n",
       "565          0.09780           0.10340         0.14400              0.09791   \n",
       "566          0.08455           0.10230         0.09251              0.05302   \n",
       "567          0.11780           0.27700         0.35140              0.15200   \n",
       "568          0.05263           0.04362         0.00000              0.00000   \n",
       "\n",
       "     ...  radius_worst  texture_worst  perimeter_worst  area_worst  \\\n",
       "0    ...        25.380          17.33           184.60      2019.0   \n",
       "1    ...        24.990          23.41           158.80      1956.0   \n",
       "2    ...        23.570          25.53           152.50      1709.0   \n",
       "3    ...        14.910          26.50            98.87       567.7   \n",
       "4    ...        22.540          16.67           152.20      1575.0   \n",
       "..   ...           ...            ...              ...         ...   \n",
       "564  ...        25.450          26.40           166.10      2027.0   \n",
       "565  ...        23.690          38.25           155.00      1731.0   \n",
       "566  ...        18.980          34.12           126.70      1124.0   \n",
       "567  ...        25.740          39.42           184.60      1821.0   \n",
       "568  ...         9.456          30.37            59.16       268.6   \n",
       "\n",
       "     smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0             0.16220            0.66560           0.7119   \n",
       "1             0.12380            0.18660           0.2416   \n",
       "2             0.14440            0.42450           0.4504   \n",
       "3             0.20980            0.86630           0.6869   \n",
       "4             0.13740            0.20500           0.4000   \n",
       "..                ...                ...              ...   \n",
       "564           0.14100            0.21130           0.4107   \n",
       "565           0.11660            0.19220           0.3215   \n",
       "566           0.11390            0.30940           0.3403   \n",
       "567           0.16500            0.86810           0.9387   \n",
       "568           0.08996            0.06444           0.0000   \n",
       "\n",
       "     concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "0                  0.2654          0.4601                  0.11890  \n",
       "1                  0.1860          0.2750                  0.08902  \n",
       "2                  0.2430          0.3613                  0.08758  \n",
       "3                  0.2575          0.6638                  0.17300  \n",
       "4                  0.1625          0.2364                  0.07678  \n",
       "..                    ...             ...                      ...  \n",
       "564                0.2216          0.2060                  0.07115  \n",
       "565                0.1628          0.2572                  0.06637  \n",
       "566                0.1418          0.2218                  0.07820  \n",
       "567                0.2650          0.4087                  0.12400  \n",
       "568                0.0000          0.2871                  0.07039  \n",
       "\n",
       "[569 rows x 32 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_breast_cancer = pd.read_csv(\"breast-cancer.csv\")\n",
    "df_breast_cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "radius_mean = df_breast_cancer[\"radius_mean\"].values\n",
    "area_mean\t = df_breast_cancer[\"area_mean\"].values\n",
    "perimeter_mean = df_breast_cancer[\"perimeter_mean\"].values\n",
    "concave_points_mean = df_breast_cancer[\"concave points_mean\"].values\n",
    "\n",
    "diagnosis = df_breast_cancer[\"diagnosis\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos colocar os atributos em uma matriz e os target em uma lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "atributos = [[i, j, k, l] for i, j, k, l in zip(radius_mean, area_mean, perimeter_mean, concave_points_mean)]\n",
    "target = diagnosis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### vamos agora aplicar o Label Encoder para dados binários:\n",
    "\n",
    "##### 1 - para tumores malignos\n",
    "##### 0 - para tumores benigno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = target.reshape(-1,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\glauber24022\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\preprocessing\\_label.py:114: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "encoder = LabelEncoder()\n",
    "codificados = encoder.fit_transform(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como o dataset é imenso, vou fazer dois splits de dados para ter apenas uma porcentagem do dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "569"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_treino, X_teste, y_treino, y_teste = train_test_split(atributos, codificados, test_size=0.1, random_state=2020)\n",
    "\n",
    "len(y_treino)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_treino, X_teste, y_treino, y_teste = train_test_split(X_teste, y_teste, test_size=0.2, random_state=2020)\n",
    "\n",
    "len(y_treino)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nomalizando o dados de treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler() #normalizador padrão\n",
    "\n",
    "X_treino_norm = scaler.fit_transform(X_treino)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_teste_norm = scaler.transform(X_teste)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classe Valor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A classe valor foi baseada de acordo com a classe realizada no vídeo do professor e no notebook ATP-303 NN 4.2 - Notebook MLP.\n",
    "\n",
    "\n",
    "Foi necessário a implementação de novos métodos para o funcionamento correto da classe Valor no resto do código."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Valor:\n",
    "    def __init__(self, data, progenitor=(), operador_mae=\"\", rotulo=\"\"):\n",
    "        self.data = data\n",
    "        self.progenitor = progenitor\n",
    "        self.operador_mae = operador_mae\n",
    "        self.rotulo = rotulo\n",
    "        self.grad = 0\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"Valor(data={self.data})\"\n",
    "    \n",
    "    def __add__(self, outro_valor):\n",
    "        \"\"\"Realiza a operação: self + outro_valor.\"\"\"\n",
    "        \n",
    "        if not isinstance(outro_valor, Valor):\n",
    "            outro_valor = Valor(outro_valor)\n",
    "            \n",
    "        progenitor = (self, outro_valor)\n",
    "        data = self.data + outro_valor.data\n",
    "        operador_mae = \"+\"\n",
    "        resultado = Valor(data, progenitor, operador_mae)\n",
    "        \n",
    "        def propagar_adicao():\n",
    "            self.grad += resultado.grad\n",
    "            outro_valor.grad += resultado.grad\n",
    "            \n",
    "        resultado.propagar = propagar_adicao\n",
    "        \n",
    "        return resultado\n",
    "    \n",
    "    def __mul__(self, outro_valor):\n",
    "        \"\"\"Realiza a operação: self * outro_valor.\"\"\"\n",
    "        \n",
    "        if not isinstance(outro_valor, Valor):\n",
    "            outro_valor = Valor(outro_valor)\n",
    "            \n",
    "        progenitor = (self, outro_valor)\n",
    "        data = self.data * outro_valor.data\n",
    "        operador_mae = \"*\"\n",
    "        resultado = Valor(data, progenitor, operador_mae)\n",
    "        \n",
    "        def propagar_multiplicacao():\n",
    "            self.grad += resultado.grad * outro_valor.data \n",
    "            outro_valor.grad += resultado.grad * self.data\n",
    "            \n",
    "        resultado.propagar = propagar_multiplicacao\n",
    "        \n",
    "        return resultado\n",
    "    \n",
    "    def exp(self):\n",
    "        \"\"\"Realiza a operação: exp(self)\"\"\"\n",
    "        progenitor = (self, )\n",
    "        data = math.exp(self.data)\n",
    "        operador_mae = \"exp\"\n",
    "        resultado = Valor(data, progenitor, operador_mae)\n",
    "        \n",
    "        def propagar_exp():\n",
    "            self.grad += resultado.grad * data \n",
    "        \n",
    "        resultado.propagar = propagar_exp\n",
    "        \n",
    "        return resultado\n",
    "    \n",
    "    def __pow__(self, expoente):\n",
    "        \"\"\"Realiza a operação: self ** expoente\"\"\"\n",
    "        assert isinstance(expoente, (int, float))\n",
    "        progenitor = (self, )\n",
    "        data = self.data ** expoente\n",
    "        operador_mae = f\"**{expoente}\"\n",
    "        resultado = Valor(data, progenitor, operador_mae)\n",
    "        \n",
    "        def propagar_pow():\n",
    "            self.grad += resultado.grad * (expoente * self.data ** (expoente - 1))\n",
    "        \n",
    "        resultado.propagar = propagar_pow\n",
    "        \n",
    "        return resultado\n",
    "    \n",
    "    def __truediv__(self, outro_valor):\n",
    "        \"\"\"Realiza a operação: self / outro_valor\"\"\"\n",
    "        return self * outro_valor ** (-1)\n",
    "    \n",
    "    def __neg__(self):\n",
    "        \"\"\"Realiza a operação: -self\"\"\"\n",
    "        return self * -1\n",
    "    \n",
    "    def __sub__(self, outro_valor):\n",
    "        \"\"\"Realiza a operação: self - outro_valor\"\"\"\n",
    "        return self + (-outro_valor)\n",
    "    \n",
    "    def __rsub__(self, outro):\n",
    "        if not isinstance(outro, Valor):\n",
    "            outro = Valor(outro)\n",
    "        return Valor(outro.data - self.data)\n",
    "    \n",
    "    def __radd__(self, outro_valor):\n",
    "        \"\"\"Realiza a operação: outro_valor + self\"\"\"\n",
    "        return self + outro_valor\n",
    "    \n",
    "    def __rmul__(self, outro_valor):\n",
    "        \"\"\"Realiza a operação: outro_valor * self\"\"\"\n",
    "        return self * outro_valor\n",
    "    \n",
    "    def sig(self):\n",
    "        \"\"\"Realiza a operação: exp(self) / (exp(self) + 1)\"\"\"\n",
    "        return self.exp() / (self.exp() + 1)\n",
    "    \n",
    "    def log(self):\n",
    "        \"\"\"Realiza a operação: Log(self.data)\"\"\"\n",
    "        return Valor(math.log(self.data))\n",
    "    \n",
    "    def propagar(self):\n",
    "        pass\n",
    "\n",
    "    def __gt__(self, outro_valor):\n",
    "        \"\"\"Realiza a operação maior que\"\"\"\n",
    "        if not isinstance(outro_valor, Valor):\n",
    "            outro_valor = Valor(outro_valor)\n",
    "        return self.data > outro_valor.data\n",
    "\n",
    "    def __lt__(self, outro_valor):\n",
    "        \"\"\"Realiza a operação menor que\"\"\"\n",
    "        if not isinstance(outro_valor, Valor):\n",
    "            outro_valor = Valor(outro_valor)\n",
    "        return self.data < outro_valor.data\n",
    "    \n",
    "    def __int__(self):\n",
    "        \"\"\"Realiza a transformação para inteiro\"\"\"\n",
    "        return int(self.data)\n",
    "    \n",
    "    def propagar_tudo(self):\n",
    "        \n",
    "        self.grad = 1\n",
    "        \n",
    "        ordem_topologica = []\n",
    "        \n",
    "        visitados = set()\n",
    "\n",
    "        def constroi_ordem_topologica(v):\n",
    "            if v not in visitados:\n",
    "                visitados.add(v)\n",
    "                for progenitor in v.progenitor:\n",
    "                    constroi_ordem_topologica(progenitor)\n",
    "                ordem_topologica.append(v)\n",
    "\n",
    "        constroi_ordem_topologica(self)\n",
    "        \n",
    "        for vertice in reversed(ordem_topologica):\n",
    "            vertice.propagar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classe Neurônio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A classe Neurônio foi baseada de acordo com a classe realizada no vídeo do professor e no notebook ATP-303 NN 4.2 - Notebook MLP.\n",
    "\n",
    "\n",
    "Não foi necessário a implementação de novos métodos para o funcionamento correto da classe Neurônio no resto do código."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neuronio:\n",
    "    def __init__(self, num_dados_entrada):\n",
    "        self.vies = Valor(random.uniform(-1, 1))\n",
    "        \n",
    "        self.pesos = []\n",
    "        for i in range(num_dados_entrada):\n",
    "            self.pesos.append(Valor(random.uniform(-1, 1)))\n",
    "            \n",
    "    def __call__(self, x):\n",
    "        \n",
    "        assert len(x) == len(self.pesos)\n",
    "        \n",
    "        soma = 0\n",
    "        for info_entrada, peso_interno in zip(x, self.pesos):\n",
    "            soma += info_entrada * peso_interno\n",
    "            \n",
    "        soma += self.vies  \n",
    "        dado_de_saida = soma.sig()\n",
    "        \n",
    "        return dado_de_saida       \n",
    "    \n",
    "    def parametros(self):\n",
    "        return self.pesos + [self.vies]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classe Camada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A classe Camada foi baseada de acordo com a classe realizada no vídeo do professor e no notebook ATP-303 NN 4.2 - Notebook MLP.\n",
    "\n",
    "\n",
    "Não foi necessário a implementação de novos métodos para o funcionamento correto da classe Valor no resto do código."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Camada:\n",
    "    def __init__(self, num_neuronios, num_dados_entrada):\n",
    "        neuronios = []\n",
    "        \n",
    "        for _ in range(num_neuronios):\n",
    "            neuronio = Neuronio(num_dados_entrada)\n",
    "            neuronios.append(neuronio)\n",
    "            \n",
    "        self.neuronios = neuronios     \n",
    "        \n",
    "    def __call__(self, x):\n",
    "        dados_de_saida = []\n",
    "        \n",
    "        for neuronio in self.neuronios:\n",
    "            informacao = neuronio(x)\n",
    "            dados_de_saida.append(informacao)\n",
    "            \n",
    "        if len(dados_de_saida) == 1:\n",
    "            return dados_de_saida[0]\n",
    "        else:        \n",
    "            return dados_de_saida  \n",
    "    \n",
    "    def parametros(self):\n",
    "        params = []\n",
    "        \n",
    "        for neuronio in self.neuronios:\n",
    "            params_neuronio = neuronio.parametros()\n",
    "            params.extend(params_neuronio)\n",
    "        \n",
    "        return params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MLP\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A classe MLP foi baseada de acordo com a classe realizada no vídeo do professor e no notebook ATP-303 NN 4.2 - Notebook MLP.\n",
    "\n",
    "\n",
    "Não foi necessário a implementação de novos métodos para o funcionamento correto da classe no resto do código."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP:\n",
    "    def __init__(self, num_dados_entrada, num_neuronios_por_camada):\n",
    "        \n",
    "        percurso = [num_dados_entrada] + num_neuronios_por_camada\n",
    "        \n",
    "        camadas = []\n",
    "        \n",
    "        for i in range(len(num_neuronios_por_camada)):\n",
    "            camada = Camada(num_neuronios_por_camada[i], percurso[i])\n",
    "            camadas.append(camada)\n",
    "            \n",
    "        self.camadas = camadas\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        for camada in self.camadas:\n",
    "            x = camada(x)\n",
    "        return x\n",
    "    \n",
    "    def parametros(self):\n",
    "        params = []\n",
    "        \n",
    "        for camada in self.camadas:\n",
    "            parametros_camada = camada.parametros()\n",
    "            params.extend(parametros_camada)\n",
    "            \n",
    "        return params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Treinando o modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os dados apresentados abaixo fazem parte da arquitetura da Rede Neural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_DADOS_DE_ENTRADA = 4  \n",
    "NUM_DADOS_DE_SAIDA = 1    \n",
    "CAMADAS_OCULTAS = [4, 2]  \n",
    "\n",
    "arquitetura_da_rede = CAMADAS_OCULTAS + [NUM_DADOS_DE_SAIDA]\n",
    "\n",
    "mlp_diagnostica = MLP(NUM_DADOS_DE_ENTRADA, arquitetura_da_rede)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para Redes Neurais Classificadoras, o que muda da Rede Neural Regressora é justamente a função de perda.\n",
    "\n",
    "Nesse caso, vou usar a função Binary Cross Entropy (BCE)(Entropia Cruzada) para a função de perda.\n",
    "\n",
    "O papel da função de custo é retornar valores altos para previsões ruins e valores baixos para previsões boas. Por isso, queremos chegar o mais próximo do 0 possivel!\n",
    "\n",
    "Mas por que vamos usar a BCE?\n",
    "\n",
    "Pois ele lida bem com probabilidades, penaliza as previsões erradas com muita confiança e é diferenciável, ou seja, permite o cálculo do gradiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_cross_entropy(y_true, y_pred):\n",
    "    # Adiciona epsilon para evitar log(0)\n",
    "    epsilon = 1e-7\n",
    "\n",
    "    # Clamping manual (Valor não aceita min/max direto)\n",
    "    y_pred = y_pred if y_pred > epsilon else Valor(epsilon)\n",
    "    y_pred = y_pred if y_pred < (1 - epsilon) else Valor(1 - epsilon)\n",
    "\n",
    "    # Cálculo da perda usando operadores da classe Valor\n",
    "    loss = - (y_true * y_pred.log() + (1 - y_true) * (1 - y_pred).log())\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valor(data=31.167588618636717)\n"
     ]
    }
   ],
   "source": [
    "erros = []\n",
    "\n",
    "for yt, yp in zip(y_treino, y_pred):\n",
    "    BCE = binary_cross_entropy(yt, yp)\n",
    "    erros.append(BCE)\n",
    "    \n",
    "loss = sum(erros)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 11.238006310143245\n",
      "1 11.434178831203335\n",
      "2 14.875198013488703\n",
      "3 17.786083686795312\n",
      "4 11.489202402892158\n",
      "5 14.181682171896675\n",
      "6 15.559141918404364\n",
      "7 12.610849682307617\n",
      "8 15.20672216361952\n",
      "9 13.062553628380893\n",
      "10 14.070494480255737\n",
      "11 14.171171472874539\n",
      "12 3.8631290979964183\n",
      "13 5.87695352388899\n",
      "14 2.5844523525170833\n",
      "15 3.0942722719621027\n",
      "16 3.4290117632323533\n",
      "17 4.806777761612066\n",
      "18 2.583442854401301\n",
      "19 2.8349090940645247\n",
      "20 3.443004333517494\n",
      "21 2.0859873645765825\n",
      "22 2.337224006179788\n",
      "23 2.5790043519658474\n",
      "24 2.7632406989335405\n",
      "25 2.475722434534464\n",
      "26 2.5146647468601326\n",
      "27 2.5190925662285717\n",
      "28 2.3521536957069156\n",
      "29 2.5011536805228034\n",
      "30 2.17212038191921\n",
      "31 2.4356676614721886\n",
      "32 2.04493698970238\n",
      "33 2.3498239499646725\n",
      "34 1.9973055190611928\n",
      "35 2.3096316264563157\n",
      "36 1.974782856824933\n",
      "37 2.288560704488177\n",
      "38 1.9574571906782974\n",
      "39 2.2692280363447153\n",
      "40 1.9475178483570177\n",
      "41 2.2540988812931184\n",
      "42 1.9401760132697796\n",
      "43 2.2384188245473258\n",
      "44 1.9373987136851096\n",
      "45 2.2236675058572892\n",
      "46 1.9370516285244574\n",
      "47 2.2074062767910085\n",
      "48 1.940553354584311\n",
      "49 2.190069447444342\n",
      "50 1.9469855478357316\n",
      "51 2.1700167711079255\n",
      "52 1.9571449944850736\n",
      "53 2.1467670494417836\n",
      "54 1.970493794030142\n",
      "55 2.1189892032411017\n",
      "56 1.9865641947564645\n",
      "57 2.085948718554491\n",
      "58 2.0033759415736156\n",
      "59 2.047381911319915\n",
      "60 2.0175097055235613\n",
      "61 2.004442888745939\n",
      "62 2.024398663804924\n",
      "63 1.959846162925386\n",
      "64 2.02066553174377\n",
      "65 1.9172326358354772\n",
      "66 2.0068806952695524\n",
      "67 1.8798759809270844\n",
      "68 1.9877803040099702\n",
      "69 1.8496873906742268\n",
      "70 1.9692162075548072\n",
      "71 1.8267694220653783\n",
      "72 1.9547921198297973\n",
      "73 1.8095511293839892\n",
      "74 1.9447693157290902\n",
      "75 1.7956388294533407\n",
      "76 1.9373538890700002\n",
      "77 1.7829905044484289\n",
      "78 1.9306931350791243\n",
      "79 1.7705977815533083\n",
      "80 1.923940771987069\n",
      "81 1.7583358882399178\n",
      "82 1.9171314190165873\n",
      "83 1.7464095423297987\n",
      "84 1.9105740090370584\n",
      "85 1.7349462318745232\n",
      "86 1.9044227749295979\n",
      "87 1.723910881452072\n",
      "88 1.8986203771761332\n",
      "89 1.713206473034187\n",
      "90 1.8930497483610336\n",
      "91 1.7027712228132628\n",
      "92 1.8876564189922211\n",
      "93 1.6925913907494303\n",
      "94 1.8824480756019177\n",
      "95 1.6826647090308673\n",
      "96 1.8774351671203642\n",
      "97 1.672976227542693\n",
      "98 1.8726018400981057\n",
      "99 1.6635039335416888\n",
      "100 1.8679224878757854\n",
      "101 1.65423169821692\n",
      "102 1.8633826448353057\n",
      "103 1.6451505800868835\n",
      "104 1.8589773886685055\n",
      "105 1.636252630397394\n",
      "106 1.8546998676614521\n",
      "107 1.6275284746899312\n",
      "108 1.8505392046022946\n",
      "109 1.6189696121997796\n",
      "110 1.846485936473006\n",
      "111 1.6105696722475034\n",
      "112 1.8425336884936276\n",
      "113 1.6023231814088097\n",
      "114 1.8386763227211307\n",
      "115 1.5942247362019624\n",
      "116 1.834906869826316\n",
      "117 1.5862694714281071\n",
      "118 1.8312189295869858\n",
      "119 1.5784532825573776\n",
      "120 1.8276069954594845\n",
      "121 1.570772447852103\n",
      "122 1.824065600666757\n",
      "123 1.563223493337711\n",
      "124 1.8205892431493975\n",
      "125 1.5558033132858355\n",
      "126 1.8171727498289239\n",
      "127 1.5485091149115628\n",
      "128 1.8138111247001663\n",
      "129 1.5413383169304302\n",
      "130 1.8104993672820813\n",
      "131 1.5342885607196697\n",
      "132 1.807232562622175\n",
      "133 1.5273577002005476\n",
      "134 1.8040058631685842\n",
      "135 1.5205437628431562\n",
      "136 1.8008144079668564\n",
      "137 1.5138449456185257\n",
      "138 1.797653333113943\n",
      "139 1.507259608127628\n",
      "140 1.7945177548245717\n",
      "141 1.5007862607801574\n",
      "142 1.7914027379804354\n",
      "143 1.4944235644933603\n",
      "144 1.7883032912523527\n",
      "145 1.4881703289246915\n",
      "146 1.7852143499816964\n",
      "147 1.4820255137776153\n",
      "148 1.782130763832242\n",
      "149 1.4759882335868235\n",
      "150 1.7790472881753383\n",
      "151 1.4700577640222074\n",
      "152 1.7759585739078716\n",
      "153 1.4642335518605063\n",
      "154 1.7728591613836948\n",
      "155 1.458515227475723\n",
      "156 1.769743473951954\n",
      "157 1.4529026213482132\n",
      "158 1.7666058142275214\n",
      "159 1.4473957843559135\n",
      "160 1.763440360488714\n",
      "161 1.4419950133024744\n",
      "162 1.7602411651034393\n",
      "163 1.4367008818694584\n",
      "164 1.757002152681962\n",
      "165 1.4315142787539932\n",
      "166 1.7537171196387487\n",
      "167 1.42643645329898\n",
      "168 1.7503797323039054\n",
      "169 1.4214690708028173\n",
      "170 1.746983525614866\n",
      "171 1.4166142774802115\n",
      "172 1.7435218981950504\n",
      "173 1.4118747777054859\n",
      "174 1.7399881070118008\n",
      "175 1.4072539222610947\n",
      "176 1.7363752548646696\n",
      "177 1.4027558107079419\n",
      "178 1.7326762767334452\n",
      "179 1.3983854035929315\n",
      "180 1.7288839132981053\n",
      "181 1.3941486485319252\n",
      "182 1.7249906840593194\n",
      "183 1.390052609662983\n",
      "184 1.720988838404896\n",
      "185 1.3861056072591154\n",
      "186 1.7168703108973482\n",
      "187 1.3823173450339516\n",
      "188 1.7126266384599347\n",
      "189 1.378699040062255\n",
      "190 1.7082488947564909\n",
      "191 1.375263510609019\n",
      "192 1.7037275568288797\n",
      "193 1.3720252577411012\n",
      "194 1.6990524179294115\n",
      "195 1.3690004553965902\n",
      "196 1.6942123770769122\n",
      "197 1.3662069316084962\n",
      "198 1.6891953315735733\n",
      "199 1.3636639834395485\n"
     ]
    }
   ],
   "source": [
    "NUM_EPOCAS = 200\n",
    "TAXA_DE_APRENDIZADO = 0.5\n",
    "\n",
    "for epoca in range(NUM_EPOCAS):\n",
    "    # forward pass\n",
    "    y_pred = []\n",
    "    for exemplo in X_treino_norm:\n",
    "        previsao = mlp_diagnostica(exemplo)\n",
    "        y_pred.append(previsao)\n",
    "\n",
    "    # loss\n",
    "    erros = []\n",
    "    for yt, yp in zip(y_treino, y_pred):\n",
    "        residuo = yp - yt\n",
    "        erro_quadratico = residuo ** 2\n",
    "        erros.append(erro_quadratico)        \n",
    "    loss = sum(erros)\n",
    "\n",
    "    # zero grad\n",
    "    for p in mlp_diagnostica.parametros():\n",
    "        p.grad = 0\n",
    "\n",
    "    # backpropagation\n",
    "    loss.propagar_tudo()\n",
    "\n",
    "    # atualiza parâmetros\n",
    "    for p in mlp_diagnostica.parametros():\n",
    "        p.data = p.data - p.grad * TAXA_DE_APRENDIZADO\n",
    "\n",
    "    # mostra resultado (opcional)\n",
    "    print(epoca, loss.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_teste = []\n",
    "for exemplo in X_teste_norm:\n",
    "    previsao = mlp_diagnostica(exemplo)\n",
    "    y_pred_teste.append(previsao)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Valor(data=0.9904898571586706), Valor(data=0.9905239336350088), Valor(data=0.028603679892504293), Valor(data=0.9905223572416822), Valor(data=0.02894576081738718), Valor(data=0.028472654681825173), Valor(data=0.9904651523252445), Valor(data=0.038554219997341176), Valor(data=0.9905270912218895), Valor(data=0.02848150283265805), Valor(data=0.028545044771738304), Valor(data=0.02873206292545772)]\n"
     ]
    }
   ],
   "source": [
    "print(y_pred_teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultado_final = []\n",
    "\n",
    "for i in y_pred_teste:\n",
    "    if i > Valor(0.5):\n",
    "        resultado_final.append(1)\n",
    "    else:\n",
    "        resultado_final.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_teste_lista = y_teste.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0]\n",
      "\n",
      "[1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(resultado_final)\n",
    "print()\n",
    "print(y_teste_lista)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisão: 1.00\n",
      "Acurácia: 0.92\n",
      "Sensibilidade: 0.83\n"
     ]
    }
   ],
   "source": [
    "precisao = precision_score(y_teste_lista, resultado_final)\n",
    "acuracia = accuracy_score(y_teste_lista, resultado_final)\n",
    "sensibilidade = recall_score(y_teste_lista, resultado_final)\n",
    "\n",
    "\n",
    "print(f\"Precisão: {precisao:.2f}\")\n",
    "print(f\"Acurácia: {acuracia:.2f}\")\n",
    "print(f\"Sensibilidade: {sensibilidade:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A _precisão_ identifica se os dados classificados positivos são realmente positivos, importantes para identificar falsos positivos. Nesse caso, conseguimos identificar todos os tumores malignos!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A _acurácia_ nos retorna a proporção de acertos totais. Mantivemos uma medida de acerto acima de 90%, ótimo!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A _sensibilidade_ identifica entre os positivos reais, quantos foram identificados corretamente, importantes para identificar os falsos negativos.\n",
    "Nessa caso, identificamos um tumor benigno como maligno, por isso nossa sensibilidade foi 83%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### REFERÊNCIAS:\n",
    "1. Materiais disponibilizados pelo professor.\n",
    "2. https://medium.com/ensina-ai/uma-explica%C3%A7%C3%A3o-visual-para-fun%C3%A7%C3%A3o-de-custo-binary-cross-entropy-ou-log-loss-eaee662c396c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
